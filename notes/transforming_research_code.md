# Moving beyond 'research code'
*You just inherited a codebase that does X. Minimal comments, little documentation, and written for someone's publication/thesis/side-project. You know it'll do what it was designed for, but not entirely sure it won't break when you feed it slightly different inputs. You realise you need to re-factor the code and generalise it. Here I detail the strategies that helped me re-factor code bases (after complaining a bit about the state of 'research code' in science)*

## 'Research code' is a euphemism for use-and-throw
We often inherit a piece of code from a colleague that 'does this thing'. This 'piece of code' can vary from a single file with tens of lines to a multi-file codebase. If you are lucky enough, it actually runs on your system with a just few path changes. If you are even luckier, it actually does the thing its supposed to do. The truth is however, it most likely will not do the thing *you* want it to do, and *you* will have a tough time understanding how it all makes sense. You might also be left feeling like you're the dumb one who can't figure out what's going wrong. We all know that line 'it's research code, need to figure out what is going wrong'. 

To clarify, this is not me bitching and raging on all the people who have ever shared code with me (I know I've shared 'research code' with some of you reading). Yes, not all code needs to be production-perfect or written to industry standard, and yet I do see lots of scope for improval. This is me openly describing the situation as it stands, and I'm very sure I'm not the only one who's experienced this!

## Research code is use-and-throw, but is weirdly 'expensive'

The fact is: research code is often written to get one very specialised task done for one very specialised scenario. Its use-and-throw nature inherently means another person may not be able to run it easily or manipulate it to their own needs. A grad student writes a couple of functions for their first manuscript, once its accepted and uploaded somewhere, onto the next project. A postdoc inherits a piece of code from a previous member, they begin going through the codebase. After pulling their hair for a couple of weeks, they realise it'll be easier starting from scratch and re-coding it all. 

What bothers me about the 'use-and-throw' attitude to research code is that it is not *cheap* by any metric you use to measure it. Time, effort, innovation - all of it often goes into writing research code, whether it be a statistical analysis or a method to identify your study animal from an image or recording.

## From 'use-and-throw' to 'use-and-share'
I have also worked with various forms of 'research code', most of it that I inherited from my past-self (anything code I haven't worked with for three months is out of my working memory), and some of it from colleagues, mentors or just random code I found on the internet.I have in general been interested in the idea of making the code we write more rigorous, acessible and easy to share. As suggested by previous publications [REFS], it is completely true that using basic methods like version control, unit-testing and documenting code, any codebase becomes easier to handle. 

While the methods detailed here are not new, I still do think this post may be interested for those of you who have a nice piece of code that was designed for task x.1.2, but is very likely generalisable to task X. I'm hoping the steps outlined below will allow you to convert the code from 'use-and-throw' to 'use-and-share'. While I suggest ways to transform the code, the same steps can be used to avoid the issues that cause the need for transformation hopefully.

### Steps

1. Document, document, document: Any piece of code is very likely to have a few main functions that do the heavy lifting. Understand what the expected inputs and outputs are, and write them down. If it means sitting with the original person who wrote the code, then try to make the time for it as soon as you get the code. Remember, the details of how code works is often forgotten over the long-term. So, even if you thought you understood how it all worked when the author explained it all to you, this knowledge will vapourise when you need it a few months down the line. Examples of things to document are: compulsory and optional inputs, if optional what are the default values? Input object types (integer, float, complex number, array) and lengths/dimensions (number of entries or rowxcolumn dimensions). Not sure how your documentation should look like, well just blindly copy one of the conventions used by an established package in your computer language of choice. I for instance use the Numpy convention to write docstrings in Python. 

1. Testing allows you to build without breaking: Another classic dialogue "it worked for me, I'm  sure you can fiddle around a bit for your case". It's awesome when you see it does indeed work for your case, but the code needs a bit more fiddling. So you start fiddling around, renaming variables, removing some (what you think are) unnecessary parameters, and in no time nothing seems to work. A lot of things have changed, and there's no coming back it seems. Things do break often, and that's not bad - as long as you can trace why and when. Start by writing unit-tests for all of the important functions in your code base. Imagine the ```reshape_weather_data``` takes in three variables ```temperature, weather, operator```. Somewhere along the way, you go on to remove ```operator``` input requirement. ```reshape_weather_data``` weather data still works as a function - but there may be some downstream functions that rely on the ```operator``` variable being included in their input. You can of course figure it all out by some good old debugging, but this is pretty intensive. Instead imagine this. You write unit-tests for ```reshape_weather_data```. When you next make the alteration to the inputs and run tests, you immediately get an error message saying the number of inputs don't match. Now you're alerted, and you *know* where the problem was. Much easier no? This speed-up in change-detection only increases with every change you make to the codebase. 

1. Remove hard-coded paths and values: Unless there's a very very very good reason for values to be hard-coded (value designated manually in the code), don't do it. Perhaps there's some kind of situation where you know a value is a physical constant that'll never need to be changed, okay. Otherwise, just don't. The same applies for file and object paths. Avoid file paths like the plague. It is an obvious way to make your own code fail when you run it onto another system, forget about when someone else tries to run it. Any kind of number of file path/string should raise eyebrows, and you must try to eliminate them. Your future user (most likely your future-self) would likely be using the codebase with a completely different directory structure than you do.

1. Remove file-writing side effects: You know that thing where you write a function ```process_raw_data``` that takes in raw data, cleans it up and writes it into a csv file, and returns nothing? That's a classic side effect in a function. It seems pretty harmless right, you just wrote a file - and this means you can load it in later, or actually open it in another software (OpenOffice or Excel for example)! Well, the fact is it makes your life later on a bit more complicated. Imagine you now run ```generate_density_map```, which reads the csv file generated by ```process_raw_data```, but you forgot to run ```process_raw_data``` before. You're unintentionally feeding in an older pre-existing, hard-to-track input - with potential for serious error. Preferably get rid of any file-writing patterns, unless absolutely necessary, and also try to output the to-be-written data as an object (dataframe, dictionary, etc.). Having well-defined input and output objects allows you and another person to clearly predict and check what goes in and comes out. Of course, if the function outputs can't be stored in memory due to size or time and must be written to disk - then perhaps a proper scheme to avoid confusion in execution order. 

1. Alter names to be meaningful: Anyone who's begun to work with a piece of code with variables named 'va', 'fm', or the classic 'x' will at some point start to worry about the time when this code needs to be refactored. Short variable names are a historical and cultural artifact of the first computing systems which had small screens and thus necessitated the use of very short variables. We are now in the age of comfortably sized monitors, even ultra-wide ones in fact. There are no real reasons to continue this historically contingent practice. Yes, I too learnt to name my variables 'xx1', 'xx2, etc. just like many of you, but it doesn't make sense once you stop and start to think about where the practice comes from. Instead of 'va' isn't 'vertical_alignment' better, doesn't 'fundamental_matrix' make so much more sense than 'fm'? 

1. Include as many references as you go: Especially if you're working with code implementing a new method, your code will probably rely on concepts, ideas and methods from previously published literature. As happens in science, it may be no surprise to realise that what some people call a 'central body', others will call 'common body', and then someone will also come up with the more general term 'circular body'. Now combine working with short variable names where the variable 'c_body' appears in different functions, and likely has slightly different meanings in each situation. Ideally, of course, the 'c_body' could have been name something more informative. Given that we still have the 'c_body' variable spread over more multiple functions - what could have helped to make sense -- references! A short reference as part of the function documentation saying 'c_body in this function refers to the central body in ABC et al. 2022' goes a long way in explaining to your future self, or the next person who comes along. 

## Overview
To summarise, 'research code' is often a proof-of-principle thing. Despite it being proof-of-principle, I argue that it shouldn't imply 'hard-to-generalise' or 'difficult-to-understand'! All 'research code' is admittedly written under a time-constraint, projects need to be submitted by the end of the semester, PhD, postdoc and project funding timelines. 

## Acknowledgements
I'd like to thank XX, YY, ZZ for .
